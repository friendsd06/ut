import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.broadcast.Broadcast;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import java.io.*;
import java.nio.file.*;
import java.util.Base64;

public class DatabricksJKSWithBroadcast {

    private static Broadcast<String> truststoreBroadcast;
    private static Broadcast<String> keystoreBroadcast;

    /**
     * Read JKS from resources and broadcast as Base64 string
     */
    private static void broadcastJKSFiles(SparkSession spark) throws IOException {
        JavaSparkContext jsc = JavaSparkContext.fromSparkContext(spark.sparkContext());

        // Read truststore.jks from src/main/resources/ as Base64
        InputStream is1 = DatabricksJKSWithBroadcast.class
            .getClassLoader()
            .getResourceAsStream("truststore.jks");
        byte[] truststoreBytes = is1.readAllBytes();
        String truststoreBase64 = Base64.getEncoder().encodeToString(truststoreBytes);
        is1.close();

        // Read keystore.jks from src/main/resources/ as Base64
        InputStream is2 = DatabricksJKSWithBroadcast.class
            .getClassLoader()
            .getResourceAsStream("keystore.jks");
        byte[] keystoreBytes = is2.readAllBytes();
        String keystoreBase64 = Base64.getEncoder().encodeToString(keystoreBytes);
        is2.close();

        // Broadcast to all nodes
        truststoreBroadcast = jsc.broadcast(truststoreBase64);
        keystoreBroadcast = jsc.broadcast(keystoreBase64);
    }

    /**
     * Get truststore path (converts broadcast Base64 to file)
     */
    private static String getTruststorePath() throws IOException {
        String base64 = truststoreBroadcast.value();
        byte[] bytes = Base64.getDecoder().decode(base64);
        Path tempFile = Files.createTempFile("truststore", ".jks");
        Files.write(tempFile, bytes);
        return tempFile.toString();
    }

    public static void main(String[] args) throws IOException {

        // Create Spark Session
        SparkSession spark = SparkSession.builder()
            .appName("DatabricksJKSWithBroadcast")
            .master("local[*]")
            .getOrCreate();

        // Broadcast JKS files from resources
        broadcastJKSFiles(spark);

        // Get truststore path (will work on both driver and executors)
        String trustStorePath = getTruststorePath();

        // Your Databricks parameters
        String jdbcUrl = "jdbc:databricks://your-workspace.cloud.databricks.com:443/default";
        String httpPath = "/sql/1.0/warehouses/your-warehouse-id";
        String token = System.getenv("DATABRICKS_TOKEN");
        String trustStorePassword = "changeit";

        // Read from Databricks warehouse with SSL - YOUR EXACT CODE
        Dataset<Row> df = spark.read()
            .format("jdbc")
            .option("driver", "com.databricks.client.jdbc.Driver")
            .option("url", jdbcUrl)
            .option("httpPath", httpPath)
            .option("dbtable", "catalog.schema.table_name")
            .option("AuthMech", "3")
            .option("UID", "token")
            .option("PWD", token)
            .option("SSL", "1")
            .option("SSLTrustStore", trustStorePath)
            .option("SSLTrustStorePwd", trustStorePassword)
            .option("SSLTrustStoreType", "JKS")
            .option("numPartitions", "4")
            .load();

        // Show results
        df.show(10);

        // Process on executors
        df.foreachPartition(partition -> {
            // Get truststore on executor from broadcast
            String execTruststore = getTruststorePath();
            // Processing logic here
        });

        spark.stop();
    }
}