-- Create DataProduct table
CREATE TABLE DataProduct (
    ProductID VARCHAR(50) PRIMARY KEY,
    ProductName VARCHAR(255)
);

-- Create DataProductLine table
CREATE TABLE DataProductLine (
    ProductLineID VARCHAR(50) PRIMARY KEY,
    ProductID VARCHAR(50),
    ProductLineName VARCHAR(255),
    FOREIGN KEY (ProductID) REFERENCES DataProduct(ProductID)
);

-- Create Datasets table
CREATE TABLE Datasets (
    DatasetID VARCHAR(50) PRIMARY KEY,
    ProductLineID VARCHAR(50),
    DatasetName VARCHAR(255),
    FOREIGN KEY (ProductLineID) REFERENCES DataProductLine(ProductLineID)
);

-- Create Slice table
CREATE TABLE Slice (
    SliceID VARCHAR(50) PRIMARY KEY,
    ProductLineID VARCHAR(50),
    SliceName VARCHAR(255),
    FOREIGN KEY (ProductLineID) REFERENCES DataProductLine(ProductLineID)
);

-- Create FeedFile table
CREATE TABLE FeedFile (
    DatasetID VARCHAR(50),
    SliceID VARCHAR(50),
    SourceSystemID VARCHAR(50),
    FeedGroup VARCHAR(50),
    FileName VARCHAR(255),
    PRIMARY KEY (DatasetID, SliceID),
    FOREIGN KEY (DatasetID) REFERENCES Datasets(DatasetID),
    FOREIGN KEY (SliceID) REFERENCES Slice(SliceID)
);

-- Create SourceSystem table
CREATE TABLE SourceSystem (
    SourceSystemID VARCHAR(50) PRIMARY KEY,
    SourceSystemName VARCHAR(255)
);

-- Create TableDataset table
CREATE TABLE TableDataset (
    DatasetID VARCHAR(50),
    TableName VARCHAR(255),
    PRIMARY KEY (DatasetID),
    FOREIGN KEY (DatasetID) REFERENCES Datasets(DatasetID)
);
===============================================================================
-- Create TableDataset table (if not already created)
CREATE TABLE TableDataset (
    DatasetID VARCHAR(50) PRIMARY KEY,
    TableName VARCHAR(255)
);

-- Create Pipeline table
CREATE TABLE Pipeline (
    PipelineID VARCHAR(50) PRIMARY KEY,
    PipelineName VARCHAR(255),
    PipelineGroup VARCHAR(50),
    PipelinePriority INT,
    SliceID VARCHAR(50),
    TemplateID VARCHAR(50),
    FOREIGN KEY (SliceID) REFERENCES Slice(SliceID),
    FOREIGN KEY (TemplateID) REFERENCES Template(TemplateID)
);

-- Create Template table
CREATE TABLE Template (
    TemplateID VARCHAR(50) PRIMARY KEY,
    TemplateName VARCHAR(255)
);

-- Create Tasks table
CREATE TABLE Tasks (
    TemplateID VARCHAR(50),
    TaskID VARCHAR(50),
    TaskName VARCHAR(255),
    PRIMARY KEY (TemplateID, TaskID),
    FOREIGN KEY (TemplateID) REFERENCES Template(TemplateID)
);

-- Create PipelineDatasets table
CREATE TABLE PipelineDatasets (
    PipelineID VARCHAR(50),
    DatasetID VARCHAR(50),
    DatasetEntryType VARCHAR(50), -- IN or OUT
    PRIMARY KEY (PipelineID, DatasetID),
    FOREIGN KEY (PipelineID) REFERENCES Pipeline(PipelineID),
    FOREIGN KEY (DatasetID) REFERENCES Datasets(DatasetID)
);

================================================================

-- Update the Pipeline table
CREATE TABLE Pipeline (
    PipelineID VARCHAR(50) PRIMARY KEY,
    PipelineName VARCHAR(255),
    PipelineGroup VARCHAR(50),
    PipelinePriority INT,
    SliceID VARCHAR(50),
    TemplateID VARCHAR(50),
    dag_id VARCHAR NOT NULL,
    owner VARCHAR NOT NULL,
    description TEXT,
    schedule_interval VARCHAR NOT NULL,
    start_date TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    end_date TIMESTAMP WITHOUT TIME ZONE,
    catchup BOOLEAN DEFAULT false,
    tags JSONB DEFAULT '[]'::jsonb,
    max_active_runs INTEGER DEFAULT 1,
    default_args JSONB DEFAULT '{}'::jsonb,
    concurrency INTEGER,
    is_active BOOLEAN DEFAULT true,
    is_paused BOOLEAN DEFAULT false,
    environment env_type DEFAULT 'dev'::env_type,
    depends_on_past BOOLEAN DEFAULT false,
    wait_for_downstream BOOLEAN DEFAULT false,
    email_on_failure BOOLEAN DEFAULT true,
    email_on_retry BOOLEAN DEFAULT false,
    retries INTEGER DEFAULT 3,
    retry_delay INTERVAL DEFAULT '00:05:00'::interval,
    sla INTERVAL,
    on_success_callback TEXT,
    on_failure_callback TEXT,
    created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (SliceID) REFERENCES Slice(SliceID),
    FOREIGN KEY (TemplateID) REFERENCES Template(TemplateID)
);



-- Update the Tasks table
CREATE TABLE Tasks (
    task_id VARCHAR NOT NULL,
    PipelineID VARCHAR NOT NULL,
    operator_type operator_type NOT NULL, -- Custom enum for operator types
    task_params JSONB DEFAULT '{}'::jsonb,
    python_callable TEXT,
    bash_command TEXT,
    sql_query TEXT,
    trigger_rule trigger_rule_type DEFAULT 'all_success'::trigger_rule_type, -- Custom enum for trigger rules
    retries INTEGER DEFAULT 3,
    retry_delay INTERVAL DEFAULT '00:05:00'::interval,
    priority_weight INTEGER DEFAULT 1,
    queue VARCHAR,
    pool VARCHAR DEFAULT 'default_pool',
    execution_timeout INTERVAL,
    depends_on_past BOOLEAN DEFAULT false,
    wait_for_downstream BOOLEAN DEFAULT false,
    email_on_failure BOOLEAN DEFAULT true,
    email_on_retry BOOLEAN DEFAULT false,
    on_success_callback TEXT,
    on_failure_callback TEXT,
    on_retry_callback TEXT,
    sla INTERVAL,
    group_id INTEGER,
    doc TEXT,
    doc_md TEXT,
    doc_rst TEXT,
    doc_json TEXT,
    doc_yaml TEXT,
    CONSTRAINT task_configs_pkey PRIMARY KEY (task_id, PipelineID),
    CONSTRAINT task_configs_pipeline_fkey FOREIGN KEY (PipelineID)
        REFERENCES public.Pipeline (PipelineID) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
);

======================================

-- Updated PipelineDatasets table
CREATE TABLE PipelineDatasets (
    id SERIAL PRIMARY KEY, -- Unique identifier for each row
    PipelineID VARCHAR(50),
    DatasetID VARCHAR(50),
    DatasetEntryType VARCHAR(50), -- IN or OUT
    upstream_task_id VARCHAR, -- Task ID for the upstream task
    downstream_task_id VARCHAR, -- Task ID for the downstream task
    dependency_type VARCHAR DEFAULT 'direct', -- Type of dependency (default is 'direct')
    is_active BOOLEAN DEFAULT true, -- Indicates if the dependency is active
    created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP, -- Timestamp for record creation
    CONSTRAINT pipeline_datasets_pipelineid_fkey FOREIGN KEY (PipelineID)
        REFERENCES Pipeline(PipelineID) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION,
    CONSTRAINT pipeline_datasets_datasetid_fkey FOREIGN KEY (DatasetID)
        REFERENCES Datasets(DatasetID) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION,
    CONSTRAINT task_dependencies_dag_id_downstream_task_id_fkey FOREIGN KEY (PipelineID, downstream_task_id)
        REFERENCES public.Tasks (PipelineID, task_id) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION,
    CONSTRAINT task_dependencies_dag_id_upstream_task_id_fkey FOREIGN KEY (PipelineID, upstream_task_id)
        REFERENCES public.Tasks (PipelineID, task_id) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
);

=====================

corrected

CREATE TABLE Pipeline (
    PipelineID VARCHAR(50) PRIMARY KEY,
    PipelineName VARCHAR(255),
    PipelineGroup VARCHAR(50),
    PipelinePriority INT,
    SliceID VARCHAR(50),
    TemplateID VARCHAR(50),
    dag_id VARCHAR NOT NULL,
    owner VARCHAR NOT NULL,
    description TEXT,
    schedule_interval VARCHAR NOT NULL,
    start_date TIMESTAMP WITHOUT TIME ZONE NOT NULL,
    end_date TIMESTAMP WITHOUT TIME ZONE,
    catchup BOOLEAN DEFAULT false,
    tags JSONB DEFAULT '[]'::jsonb,
    max_active_runs INTEGER DEFAULT 1,
    default_args JSONB DEFAULT '{}'::jsonb,
    concurrency INTEGER,
    is_active BOOLEAN DEFAULT true,
    is_paused BOOLEAN DEFAULT false,
    depends_on_past BOOLEAN DEFAULT false,
    wait_for_downstream BOOLEAN DEFAULT false,
    email_on_failure BOOLEAN DEFAULT true,
    email_on_retry BOOLEAN DEFAULT false,
    retries INTEGER DEFAULT 3,
    retry_delay INTERVAL DEFAULT '00:05:00'::interval,
    sla INTERVAL,
    on_success_callback TEXT,
    on_failure_callback TEXT,
    created_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (SliceID) REFERENCES Slice(SliceID)
);


CREATE TABLE Tasks (
    task_id VARCHAR NOT NULL,
    PipelineID VARCHAR NOT NULL,
    operator_type VARCHAR NOT NULL, -- Custom enum for operator types
    task_params JSONB DEFAULT '{}'::jsonb,
    python_callable TEXT,
    bash_command TEXT,
    sql_query TEXT,
    trigger_rule VARCHAR NOT NULL, -- Custom enum for trigger rules
    retries INTEGER DEFAULT 3,
    retry_delay INTERVAL DEFAULT '00:05:00'::interval,
    priority_weight INTEGER DEFAULT 1,
    queue VARCHAR,
    pool VARCHAR DEFAULT 'default_pool',
    execution_timeout INTERVAL,
    depends_on_past BOOLEAN DEFAULT false,
    wait_for_downstream BOOLEAN DEFAULT false,
    email_on_failure BOOLEAN DEFAULT true,
    email_on_retry BOOLEAN DEFAULT false,
    on_success_callback TEXT,
    on_failure_callback TEXT,
    on_retry_callback TEXT,
    sla INTERVAL,
    group_id INTEGER,
    doc TEXT,
    doc_md TEXT,
    doc_rst TEXT,
    doc_json TEXT,
    doc_yaml TEXT,
    CONSTRAINT task_configs_pkey PRIMARY KEY (task_id, PipelineID),
    CONSTRAINT task_configs_pipeline_fkey FOREIGN KEY (PipelineID)
        REFERENCES public.Pipeline (PipelineID) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
);

CREATE TABLE IF NOT EXISTS public.slice
(
    sliceid character varying(50) COLLATE pg_catalog."default" NOT NULL,
    productlineid character varying(50) COLLATE pg_catalog."default",
    slicename character varying(255) COLLATE pg_catalog."default",
    CONSTRAINT slice_pkey PRIMARY KEY (sliceid),
    CONSTRAINT slice_productlineid_fkey FOREIGN KEY (productlineid)
        REFERENCES public.dataproductline (productlineid) MATCH SIMPLE
        ON UPDATE NO ACTION
        ON DELETE NO ACTION
)

========================
INSERT INTO public.slice (sliceid, productlineid, slicename)
VALUES
    ('SL1', 'PRLN1', 'AGXP'),
    ('SL2', 'PRLN1', 'REG1'),
    ('SL3', 'PRLN1', 'REG2');
===========================
INSERT INTO public.pipeline (
    pipelineid, pipelinename, pipelinegroup, pipelinepriority, sliceid, templateid,
    dag_id, owner, description, schedule_interval, start_date, end_date, catchup,
    tags, max_active_runs, default_args, concurrency, is_active, is_paused,
    depends_on_past, wait_for_downstream, email_on_failure, email_on_retry, retries,
    retry_delay, sla, on_success_callback, on_failure_callback, created_at, updated_at
)
VALUES
    ('PL1', 'Pipeline_AGXP', 'REG', 1, 'SL1', NULL, 'DAG1', 'owner1', 'Description 1', '0 12 * * *', '2024-01-01 12:00:00', NULL, false, '[]', 1, '{}', 5, true, false, false, false, true, false, 3, '00:05:00', NULL, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP),
    ('PL2', 'Pipeline_REG1', 'REG', 2, 'SL2', NULL, 'DAG2', 'owner2', 'Description 2', '0 14 * * *', '2024-01-01 14:00:00', NULL, false, '[]', 1, '{}', 5, true, false, false, false, true, false, 3, '00:05:00', NULL, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP),
    ('PL3', 'Pipeline_REG2', 'REG', 3, 'SL3', NULL, 'DAG3', 'owner3', 'Description 3', '0 16 * * *', '2024-01-01 16:00:00', NULL, false, '[]', 1, '{}', 5, true, false, false, false, true, false, 3, '00:05:00', NULL, NULL, NULL, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP);

    ========================

    INSERT INTO public.tasks (
        task_id, pipelineid, operator_type, task_params, python_callable, bash_command, sql_query,
        trigger_rule, retries, retry_delay, priority_weight, queue, pool, execution_timeout,
        depends_on_past, wait_for_downstream, email_on_failure, email_on_retry, on_success_callback,
        on_failure_callback, on_retry_callback, sla, group_id, doc, doc_md, doc_rst, doc_json, doc_yaml
    )
    VALUES
        ('T1', 'PL1', 'python', '{}', 'callable1', NULL, NULL, 'all_success', 3, '00:05:00', 1, 'queue1', 'default_pool', NULL, false, false, true, false, NULL, NULL, NULL, NULL, 1, 'Documentation 1', NULL, NULL, NULL, NULL),
        ('T2', 'PL2', 'bash', '{}', NULL, 'echo "Hello World"', NULL, 'all_failed', 3, '00:05:00', 1, 'queue2', 'default_pool', NULL, false, false, true, false, NULL, NULL, NULL, NULL, 2, 'Documentation 2', NULL, NULL, NULL, NULL),
        ('T3', 'PL3', 'sql', '{}', NULL, NULL, 'SELECT * FROM table', 'one_success', 3, '00:05:00', 1, 'queue3', 'default_pool', NULL, false, false, true, false, NULL, NULL, NULL, NULL, 3, 'Documentation 3', NULL, NULL, NULL, NULL);

=============================================
INSERT INTO public.pipelinedatasets (
    pipelineid, datasetid, datasetentrytype, upstream_task_id, downstream_task_id, dependency_type, is_active, created_at
)
VALUES
    ('PL1', 'DS1', 'IN', NULL, 'T1', 'direct', true, CURRENT_TIMESTAMP),
    ('PL2', 'DS2', 'OUT', 'T1', 'T2', 'direct', true, CURRENT_TIMESTAMP),
    ('PL3', 'DS3', 'IN', 'T2', 'T3', 'indirect', true, CURRENT_TIMESTAMP);


===========================
INSERT INTO public.dataproduct (productid, productname)
VALUES
    ('PR1', 'Derivatives'),
    ('PR2', 'Equities'),
    ('PR3', 'Fixed Income');
==================
INSERT INTO public.dataproductline (productlineid, productid, productlinename)
VALUES
    ('PRLN1', 'PR1', 'Derivatives Line 1'),
    ('PRLN2', 'PR2', 'Equities Line 1'),
    ('PRLN3', 'PR3', 'Fixed Income Line 1');


    ========================

    INSERT INTO public.datasets (datasetid, productlineid, datasetname)
    VALUES
        ('DS1', 'PRLN1', 'AGXP_YYYYMMDD.txt'),
        ('DS2', 'PRLN2', 'REG1_YYYYMMDD.txt'),
        ('DS3', 'PRLN3', 'REG2_YYYYMMDD.txt');

