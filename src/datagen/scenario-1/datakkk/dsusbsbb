```python
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.dummy import DummyOperator
from datetime import datetime, timedelta
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def validate_checksum(**context) -> str:
    """Validate checksum and branch"""
    time.sleep(1)
    dag_run = context['dag_run']
    is_valid = dag_run.conf.get('valid_checksum', True)
    
    if is_valid:
        return 'dsr_lookup'
    return 'stop_processing'

def perform_dsr_lookup(**context):
    """DSR lookup task"""
    time.sleep(1)

def generate_lev(**context):
    """Generate LEV IDs"""
    time.sleep(1)

def check_activation(**context) -> str:
    """Check if first or second instance"""
    time.sleep(1)
    dag_run = context['dag_run']
    is_first = dag_run.conf.get('is_first_instance', True)
    
    # Store instance type in XCom for substitution check
    context['task_instance'].xcom_push(
        key='instance_type',
        value='first' if is_first else 'second'
    )
    
    return 'first_instance' if is_first else 'second_instance'

def process_first_instance(**context):
    """Process first instance"""
    time.sleep(1)
    # Always proceed to substitution check
    return 'substitution_check'

def process_second_instance(**context):
    """Process second instance"""
    time.sleep(1)
    # Always proceed to substitution check
    return 'substitution_check'

def check_substitution(**context) -> str:
    """
    Check substitution based on instance type
    Different substitution logic for first/second instance
    """
    time.sleep(1)
    
    # Get instance type from XCom
    instance_type = context['task_instance'].xcom_pull(
        key='instance_type',
        task_ids='activation_check'
    )
    
    # Get substitution flag from DAG run config
    dag_run = context['dag_run']
    needs_substitution = dag_run.conf.get('needs_substitution', True)
    
    if needs_substitution:
        if instance_type == 'first':
            logger.info("First instance needs substitution")
        else:
            logger.info("Second instance needs substitution")
        return 'stop_for_substitution'
    return 'dump_to_s3'

def stop_processing(**context):
    """Handle invalid checksum"""
    time.sleep(1)

def stop_for_substitution(**context):
    """Handle substitution stop"""
    time.sleep(1)

def dump_to_s3(**context):
    """Dump to S3"""
    time.sleep(1)

def trigger_ingestion(**context):
    """Trigger ingestion"""
    time.sleep(1)

with DAG(
    'complete_validation_pipeline',
    default_args={
        'owner': 'airflow',
        'start_date': datetime(2024, 1, 1),
        'retries': 1
    },
    schedule_interval=None,
    catchup=False
) as dag:

    start = DummyOperator(task_id='start')

    validate = BranchPythonOperator(
        task_id='validate_file_checksum',
        python_callable=validate_checksum
    )

    stop = PythonOperator(
        task_id='stop_processing',
        python_callable=stop_processing
    )

    dsr_lookup = PythonOperator(
        task_id='dsr_lookup',
        python_callable=perform_dsr_lookup
    )

    lev_generate = PythonOperator(
        task_id='lev_generate',
        python_callable=generate_lev
    )

    activation_check = BranchPythonOperator(
        task_id='activation_check',
        python_callable=check_activation
    )

    first_instance = PythonOperator(
        task_id='first_instance',
        python_callable=process_first_instance
    )

    second_instance = PythonOperator(
        task_id='second_instance',
        python_callable=process_second_instance
    )

    substitution_check = BranchPythonOperator(
        task_id='substitution_check',
        python_callable=check_substitution,
        trigger_rule='none_failed'
    )

    stop_substitution = PythonOperator(
        task_id='stop_for_substitution',
        python_callable=stop_for_substitution
    )

    dump_s3 = PythonOperator(
        task_id='dump_to_s3',
        python_callable=dump_to_s3
    )

    trigger = PythonOperator(
        task_id='trigger_ingestion',
        python_callable=trigger_ingestion
    )

    end = DummyOperator(
        task_id='end',
        trigger_rule='none_failed'
    )

    # Set dependencies
    start >> validate
    
    # Invalid checksum path
    validate >> stop >> end
    
    # Valid checksum path
    validate >> dsr_lookup >> lev_generate >> activation_check
    
    # Instance paths
    activation_check >> [first_instance, second_instance]
    first_instance >> substitution_check
    second_instance >> substitution_check
    
    # Substitution paths
    substitution_check >> [stop_substitution, dump_s3]
    dump_s3 >> trigger >> end
    stop_substitution >> end

```