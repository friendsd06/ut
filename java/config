"""
Configuration manager for Databricks warehouse connections and S3 ETL operations
"""
from dataclasses import dataclass, field
from enum import Enum, auto
from pathlib import Path
from typing import Dict, Any, Optional
import yaml
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Environment(Enum):
    LOCAL = auto()
    DEV = auto()
    TEST = auto()
    PREPROD = auto()
    PROD = auto()

    @classmethod
    def from_string(cls, env_name: str) -> 'Environment':
        try:
            return cls[env_name.upper()]
        except KeyError:
            valid_environments = ', '.join(env.name.lower() for env in cls)
            raise ValueError(f"Invalid environment: '{env_name}'. Valid environments: {valid_environments}")

@dataclass
class DatabricksConnection:
    """Databricks warehouse connection settings"""
    hostname: str
    port: int
    transportMode: str
    ssl: str
    ConnCatalog: str
    AuthMech: str
    UseProxy: str
    UseNativeQuery: str
    ProxyHost: str
    ProxyPort: str
    httpPath: str
    SSLTrustStorePwd: Optional[str] = None
    SSLTrustStore: Optional[str] = None

    def get_connection_params(self) -> dict:
        """Get formatted connection parameters"""
        params = {
            "host": self.hostname,
            "port": self.port,
            "transport_mode": self.transportMode,
            "ssl": self.ssl == "1",
            "catalog": self.ConnCatalog,
            "auth_mechanism": int(self.AuthMech),
            "use_proxy": self.UseProxy == "1",
            "use_native_query": self.UseNativeQuery == "1",
            "proxy_host": self.ProxyHost,
            "proxy_port": int(self.ProxyPort),
            "http_path": self.httpPath
        }

        if self.SSLTrustStorePwd and self.SSLTrustStore:
            params.update({
                "ssl_trust_store_pwd": self.SSLTrustStorePwd,
                "ssl_trust_store": self.SSLTrustStore
            })

        return params

@dataclass
class S3Storage:
    """S3 storage configuration"""
    base_path: str

    def get_destination_path(self, relative_path: str) -> str:
        """Build full S3 path"""
        return str(Path(self.base_path.rstrip("/")) / relative_path.lstrip("/"))

@dataclass
class TableConfig:
    """Table ETL configuration"""
    source_query: str
    destination_path: str
    file_format: str
    write_mode: str
    reader_options: Dict[str, Any] = field(default_factory=dict)
    writer_options: Dict[str, Any] = field(default_factory=dict)

    def validate(self) -> None:
        """Validate configuration"""
        supported_formats = {"parquet", "csv", "delta", "json"}
        supported_modes = {"overwrite", "append", "ignore", "error"}

        if self.file_format.lower() not in supported_formats:
            raise ValueError(f"Unsupported format '{self.file_format}'. Use: {', '.join(supported_formats)}")

        if self.write_mode.lower() not in supported_modes:
            raise ValueError(f"Unsupported mode '{self.write_mode}'. Use: {', '.join(supported_modes)}")

    def get_reader_config(self) -> dict:
        """Get Spark reader configuration"""
        return {"format": self.file_format.lower(), **self.reader_options}

    def get_writer_config(self) -> dict:
        """Get Spark writer configuration"""
        return {
            "format": self.file_format.lower(),
            "mode": self.write_mode.lower(),
            **self.writer_options
        }

class ConfigurationManager:
    """Manages Databricks and S3 configurations"""

    def __init__(self, warehouse_config: str, etl_config: str):
        """Initialize with both configuration files"""
        self.warehouse_config = self._load_yaml(warehouse_config)
        self.etl_config = self._load_yaml(etl_config)
        self._validate_configurations()

    def _load_yaml(self, file_path: str) -> dict:
        """Load YAML configuration file"""
        try:
            with open(file_path, 'r') as f:
                return yaml.safe_load(f)
        except Exception as e:
            raise ValueError(f"Failed to load {file_path}: {str(e)}")

    def _validate_configurations(self) -> None:
        """Validate configuration structures"""
        if 'databricks' not in self.warehouse_config:
            raise ValueError("Missing databricks section in warehouse config")

        if 's3_settings' not in self.etl_config or 'tables' not in self.etl_config:
            raise ValueError("Missing required sections in ETL config")

        required_envs = {'local', 'dev', 'test', 'preprod', 'prod'}

        # Validate warehouse environments
        warehouse_envs = set(self.warehouse_config['databricks'].keys())
        missing_warehouse_envs = required_envs - warehouse_envs
        if missing_warehouse_envs:
            raise ValueError(f"Missing warehouse config for: {missing_warehouse_envs}")

        # Validate storage environments
        storage_envs = set(self.etl_config['s3_settings'].keys())
        missing_storage_envs = required_envs - storage_envs
        if missing_storage_envs:
            raise ValueError(f"Missing storage config for: {missing_storage_envs}")

    def get_warehouse_connection(self, environment: str) -> DatabricksConnection:
        """Get Databricks connection for environment"""
        env = Environment.from_string(environment)
        env_key = env.name.lower()

        if env_key not in self.warehouse_config['databricks']:
            raise ValueError(f"No warehouse config for: {env_key}")

        return DatabricksConnection(**self.warehouse_config['databricks'][env_key])

    def get_storage_config(self, environment: str) -> S3Storage:
        """Get S3 storage configuration for environment"""
        env = Environment.from_string(environment)
        env_key = env.name.lower()

        if env_key not in self.etl_config['s3_settings']:
            raise ValueError(f"No storage config for: {env_key}")

        return S3Storage(**self.etl_config['s3_settings'][env_key])

    def get_table_config(self, table_name: str) -> TableConfig:
        """Get table ETL configuration"""
        if table_name not in self.etl_config['tables']:
            raise ValueError(f"No config for table: {table_name}")

        settings = self.etl_config['tables'][table_name]
        return TableConfig(
            source_query=settings['query'],
            destination_path=settings['s3_path'],
            file_format=settings['format'],
            write_mode=settings['mode'],
            reader_options=settings.get('read_options', {}),
            writer_options=settings.get('write_options', {})
        )

    def get_destination_path(self, table_name: str, environment: str) -> str:
        """Get full S3 destination path"""
        table_config = self.get_table_config(table_name)
        storage_config = self.get_storage_config(environment)
        return storage_config.get_destination_path(table_config.destination_path)

    def list_tables(self) -> list:
        """Get list of configured tables"""
        return list(self.etl_config['tables'].keys())

def create_configuration_manager(warehouse_config: str, etl_config: str) -> ConfigurationManager:
    """Factory function to create configuration manager"""
    return ConfigurationManager(warehouse_config, etl_config)