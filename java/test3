Table of Contents
Prerequisites
Step 1: Prepare Required Files
Step 2: Create the Dockerfile
Step 3: Build and Test the Docker Image
Step 4: Push the Image to a Registry
Step 5: Write the Kubernetes YAML
Step 6: Deploy to Kubernetes
Step 7: Verify Deployment
Step 8: Production Considerations
Final Recap
<a name="prerequisites"></a>

1. Prerequisites
KIE Workbench WAR: E.g., business-central.war (or your custom name).
WildFly: We’ll use a jboss/wildfly base Docker image.
Docker installed locally to build and push images.
Kubernetes cluster access (e.g. a cloud provider, local cluster like Minikube, or Red Hat OpenShift).
(Recommended) A container registry (Docker Hub, Quay, private registry, etc.).
<a name="step1"></a>

2. Step 1: Prepare Required Files
Create a local folder, e.g. kie-workbench-docker/.
Place your business-central.war (the KIE Workbench WAR) inside it.
You’ll place a Dockerfile (and optional standalone.xml, if you want to override default config) in this same folder.
File Structure Example:

scss
Copy
kie-workbench-docker/
├─ Dockerfile
├─ business-central.war
└─ (optionally) standalone.xml
<a name="step2"></a>

3. Step 2: Create the Dockerfile
Below is a production-like Dockerfile with comments. It:

Uses jboss/wildfly as the base.
Copies the KIE Workbench WAR into the deployments folder.
Creates a KIE admin user with environment variables.
Exposes port 8080.
Runs WildFly on startup.
dockerfile
Copy
# Dockerfile: Build KIE Workbench with WildFly in a container

# 1) Use a stable WildFly base image. Adjust version as needed.
FROM jboss/wildfly:26.1.3.Final

# 2) Set environment variables for user creation.
#    In production, these might be injected at build time or passed via secrets.
ENV KIE_ADMIN_USER=kieadmin
ENV KIE_ADMIN_PASS=kieadmin1!
ENV KIE_ADMIN_ROLES=admin,rest-all

# 3) Run the WildFly add-user script to create an application user.
#    This user will have roles that allow them to log in to KIE Workbench.
RUN /opt/jboss/wildfly/bin/add-user.sh \
    --user $KIE_ADMIN_USER \
    --password $KIE_ADMIN_PASS \
    --role $KIE_ADMIN_ROLES \
    --silent

# 4) If you have a custom standalone.xml or other config, COPY it here.
#    (Uncomment if needed)
# COPY standalone.xml /opt/jboss/wildfly/standalone/configuration/

# 5) Copy the KIE Workbench WAR into the WildFly deployments directory.
COPY business-central.war /opt/jboss/wildfly/standalone/deployments/

# 6) Expose the HTTP port (WildFly default).
EXPOSE 8080

# 7) Entry point: run WildFly standalone, listening on all interfaces.
ENTRYPOINT ["/opt/jboss/wildfly/bin/standalone.sh", "-b", "0.0.0.0"]
Notes:

The ENV variables let you parameterize user creation. For more secure approaches, consider using Docker secrets or environment variables at runtime rather than in the image.
If you have an external DB and want a custom datasource, include a standalone.xml (or CLI script) and COPY it, then pass -c=standalone.xml in the entrypoint.
<a name="step3"></a>

4. Step 3: Build and Test the Docker Image
From the kie-workbench-docker/ directory:

bash
Copy
# 1) Build the image, tagging it with your registry/account name if needed.
docker build -t myorg/kie-workbench:1.0 .

# 2) Run locally to test.
#    This maps container port 8080 to host port 8080.
docker run -d -p 8080:8080 myorg/kie-workbench:1.0

# 3) Check logs to ensure it starts up successfully.
docker logs -f <container-id or name>
Validation: Open your browser to http://localhost:8080/business-central. Log in with kieadmin / kieadmin1!. If it works, you’re good.

<a name="step4"></a>

5. Step 4: Push the Image to a Registry
Next, you’ll need to push your image to a container registry so Kubernetes can pull it. Common steps:

bash
Copy
# 1) Log in to Docker Hub or your private registry
docker login

# 2) Push the image
docker push myorg/kie-workbench:1.0
Now your Docker image is hosted in your registry (e.g., Docker Hub).

<a name="step5"></a>

6. Step 5: Write the Kubernetes YAML
Create a file, e.g. kie-workbench-deployment.yaml, containing a Deployment and Service. Below is a minimal example:

yaml
Copy
# kie-workbench-deployment.yaml

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kie-workbench
  labels:
    app: kie-workbench
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kie-workbench
  template:
    metadata:
      labels:
        app: kie-workbench
    spec:
      containers:
      - name: kie-workbench
        image: myorg/kie-workbench:1.0
        ports:
        - containerPort: 8080
        # OPTIONAL: If you want environment overrides at runtime:
        # env:
        # - name: KIE_ADMIN_USER
        #   valueFrom:
        #     secretKeyRef:
        #       name: kie-secret
        #       key: KIE_ADMIN_USER
        readinessProbe:
          httpGet:
            path: /business-central
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /business-central
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: kie-workbench-service
spec:
  selector:
    app: kie-workbench
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
Explanation:

Deployment called kie-workbench with 1 replica (you can scale as needed).
Container image = myorg/kie-workbench:1.0.
Readiness / Liveness probes to check /business-central is responding.
Service exposes port 80 internally, forwarding traffic to 8080 in the Pod.
To allow external access, you can add a type: LoadBalancer to the Service or create an Ingress resource.

Example for a NodePort service:

yaml
Copy
spec:
  type: NodePort
  selector:
    app: kie-workbench
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
      nodePort: 30080
<a name="step6"></a>

7. Step 6: Deploy to Kubernetes
Log in or configure to the correct Kubernetes cluster (or namespace). E.g.:

bash
Copy
kubectl config use-context my-cluster
kubectl config set-context --current --namespace=my-namespace
Apply the YAML:

bash
Copy
kubectl apply -f kie-workbench-deployment.yaml
Wait for the Pod to start:

bash
Copy
kubectl get pods
kubectl logs -f <pod-name>
Verify the Service:

bash
Copy
kubectl get svc
<a name="step7"></a>

8. Step 7: Verify Deployment
If using a NodePort on port 30080, navigate to:
arduino
Copy
http://<NODE_IP>:30080/business-central
If using a LoadBalancer (on a cloud), check the EXTERNAL-IP from kubectl get svc.
Login with kieadmin / kieadmin1! (or whatever you set in your Dockerfile).
You should see the KIE Workbench (Business Central) welcome screen.

<a name="step8"></a>

9. Production Considerations
Database:

KIE Workbench uses an internal H2 by default for jBPM data. In production, configure an external DB (e.g. PostgreSQL, MySQL) and provide a custom standalone.xml or CLI script so WildFly can connect.
This ensures your process data is persisted across restarts.
Storage (Git):

All projects/rules/BPMN are stored in .niogit. If you scale horizontally, you’ll need a shared file system or push to an external Git server.
Alternatively, always push changes to a remote Git service for backup.
Secrets:

Avoid storing plain-text passwords in the Dockerfile. Instead, pass them at runtime via Kubernetes Secrets or environment variables.
Security:

Configure HTTPS either by using a TLS-termination at the load balancer or an Ingress with TLS.
Possibly integrate with Keycloak / LDAP for enterprise SSO.
Scalability:

KIE Workbench is typically design-time—so often run as a single instance. For runtime rule execution, you’d have KIE Servers that can be scaled.
<a name="recap"></a>

10. Final Recap
Obtain KIE Workbench WAR.
Write a Dockerfile that uses WildFly and copies the WAR, plus optionally creates an admin user.
Build and test the Docker image locally.
Push to a container registry.
Create a Deployment and Service YAML for Kubernetes.
Apply it in your cluster.
Check the Pod logs, expose the service, and login.
For production, add a database, secure secrets, and possibly set up HA or backups.
Done! You now have a production-style KIE Workbench running on WildFly in Docker, deployed to Kubernetes.