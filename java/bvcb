package com.example.s3demo.aws;

import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
import software.amazon.awssdk.core.async.AsyncRequestBody;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.s3.S3AsyncClient;
import software.amazon.awssdk.services.s3.S3Configuration;
import software.amazon.awssdk.services.s3.model.*;

import java.io.IOException;
import java.net.URI;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.*;
import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.*;
import java.util.logging.Logger;
import java.util.stream.Collectors;

/**
 * S3 uploader for LocalStack with support for both files and directories.
 */
public class S3Uploader implements AutoCloseable {
    private static final Logger LOGGER = Logger.getLogger(S3Uploader.class.getName());
    private static final long DEFAULT_PART_SIZE = 5 * 1024 * 1024; // 5 MiB

    private final S3AsyncClient s3Client;
    private final ExecutorService executorService;
    private final String localstackEndpoint;

    /**
     * Creates a new S3Uploader for LocalStack.
     *
     * @param localstackEndpoint The LocalStack endpoint URL
     */
    public S3Uploader(String localstackEndpoint) {
        this.localstackEndpoint = localstackEndpoint;
        this.s3Client = buildS3Client(localstackEndpoint);
        this.executorService = Executors.newFixedThreadPool(
                Runtime.getRuntime().availableProcessors(),
                r -> {
                    Thread t = new Thread(r, "s3-upload-worker");
                    t.setDaemon(true);
                    return t;
                });
    }

    /**
     * Build an S3AsyncClient configured for LocalStack.
     */
    private S3AsyncClient buildS3Client(String endpoint) {
        return S3AsyncClient.builder()
                .endpointOverride(URI.create(endpoint))
                .region(Region.US_EAST_1)
                .credentialsProvider(
                        StaticCredentialsProvider.create(
                                AwsBasicCredentials.create("test", "test")))
                .serviceConfiguration(
                        S3Configuration.builder()
                                .pathStyleAccessEnabled(true)
                                .build())
                .build();
    }

    /**
     * Ensures a bucket exists before uploading.
     *
     * @param bucketName The name of the bucket to check/create
     * @return CompletableFuture representing the operation
     */
    public CompletableFuture<Void> ensureBucketExists(String bucketName) {
        return s3Client.headBucket(req -> req.bucket(bucketName))
                .thenApply(response -> (Void) null)
                .exceptionallyCompose(throwable -> {
                    if (throwable.getCause() instanceof NoSuchBucketException) {
                        LOGGER.info("Bucket " + bucketName + " does not exist. Creating...");
                        return s3Client.createBucket(req -> req.bucket(bucketName))
                                .thenApply(response -> {
                                    LOGGER.info("Bucket " + bucketName + " created successfully");
                                    return (Void) null;
                                });
                    }
                    LOGGER.warning("Error checking bucket " + bucketName + ": " + throwable.getMessage());
                    return CompletableFuture.failedFuture(throwable);
                });
    }

    /**
     * Upload a file or directory to S3.
     * If the path is a directory, all files in the directory will be uploaded.
     *
     * @param path Path to the file or directory to upload
     * @param bucketName Name of the target bucket
     * @param baseKey Base key (prefix) in the bucket
     * @return CompletableFuture representing the upload operation with list of uploaded keys
     */
    public CompletableFuture<List<String>> upload(Path path, String bucketName, String baseKey) {
        if (!Files.exists(path)) {
            return CompletableFuture.failedFuture(new IOException("Path not found: " + path));
        }

        if (Files.isDirectory(path)) {
            // Upload directory
            return uploadDirectory(path, bucketName, baseKey);
        } else {
            // Upload single file
            return uploadFile(path, bucketName, baseKey)
                    .thenApply(List::of);
        }
    }

    /**
     * Upload a directory to S3.
     *
     * @param dirPath Path to the directory to upload
     * @param bucketName Name of the target bucket
     * @param baseKey Base key (prefix) in the bucket
     * @return CompletableFuture representing the upload operation with list of uploaded keys
     */
    public CompletableFuture<List<String>> uploadDirectory(Path dirPath, String bucketName, String baseKey) {
        LOGGER.info("Uploading directory: " + dirPath + " to " + bucketName + "/" + baseKey);

        return CompletableFuture.supplyAsync(() -> {
            try {
                List<Path> files = findAllFiles(dirPath);
                LOGGER.info("Found " + files.size() + " files to upload in " + dirPath);

                List<CompletableFuture<String>> uploadFutures = new ArrayList<>();

                for (Path file : files) {
                    // Determine the relative path from the base directory
                    Path relativePath = dirPath.relativize(file);
                    String key = baseKey.isEmpty()
                            ? relativePath.toString().replace('\\', '/')
                            : baseKey + "/" + relativePath.toString().replace('\\', '/');

                    uploadFutures.add(uploadFile(file, bucketName, key));
                }

                CompletableFuture<Void> allUploads = CompletableFuture.allOf(
                        uploadFutures.toArray(new CompletableFuture[0]));

                return allUploads.thenApply(v ->
                        uploadFutures.stream()
                                .map(CompletableFuture::join)
                                .collect(Collectors.toList())
                ).join();
            } catch (IOException e) {
                throw new CompletionException("Failed to upload directory: " + e.getMessage(), e);
            }
        }, executorService);
    }

    /**
     * Find all files in a directory recursively.
     */
    private List<Path> findAllFiles(Path dirPath) throws IOException {
        List<Path> result = new ArrayList<>();
        try (DirectoryStream<Path> stream = Files.newDirectoryStream(dirPath)) {
            for (Path path : stream) {
                if (Files.isDirectory(path)) {
                    result.addAll(findAllFiles(path));
                } else {
                    result.add(path);
                }
            }
        }
        return result;
    }

    /**
     * Upload a single file to S3.
     *
     * @param filePath Path to the file to upload
     * @param bucketName Name of the target bucket
     * @param key Key (path) in the bucket
     * @return CompletableFuture representing the upload operation
     */
    public CompletableFuture<String> uploadFile(Path filePath, String bucketName, String key) {
        if (!Files.exists(filePath) || Files.isDirectory(filePath)) {
            return CompletableFuture.failedFuture(new IOException("Not a valid file: " + filePath));
        }

        return CompletableFuture.supplyAsync(() -> {
            try {
                long fileSize = Files.size(filePath);
                LOGGER.info("Uploading file: " + filePath + " to " + bucketName + "/" + key + " (size: " + fileSize + " bytes)");

                if (fileSize < DEFAULT_PART_SIZE) {
                    // Small file: use single PUT operation
                    return uploadSmallFile(filePath, bucketName, key).join();
                } else {
                    // Large file: use multipart upload
                    return uploadLargeFile(filePath, bucketName, key).join();
                }
            } catch (IOException e) {
                throw new CompletionException("Failed to get file size: " + e.getMessage(), e);
            }
        }, executorService);
    }

    /**
     * Upload a small file (< 5 MiB) using a single PUT operation.
     */
    private CompletableFuture<String> uploadSmallFile(Path filePath, String bucketName, String key) {
        try {
            long fileSize = Files.size(filePath);
            LOGGER.info("Starting single-part upload for " + filePath);

            PutObjectRequest request = PutObjectRequest.builder()
                    .bucket(bucketName)
                    .key(key)
                    .build();

            return s3Client.putObject(request, AsyncRequestBody.fromFile(filePath))
                    .thenApply(response -> {
                        String eTag = response.eTag();
                        LOGGER.info("Completed upload for " + key + " with ETag: " + eTag);
                        return key;
                    });
        } catch (IOException e) {
            return CompletableFuture.failedFuture(e);
        }
    }

    /**
     * Upload a large file (â‰¥ 5 MiB) using multipart upload.
     */
    private CompletableFuture<String> uploadLargeFile(Path filePath, String bucketName, String key) {
        LOGGER.info("Starting multipart upload for " + filePath);

        return s3Client.createMultipartUpload(req -> req.bucket(bucketName).key(key))
                .thenCompose(createResponse -> {
                    String uploadId = createResponse.uploadId();
                    LOGGER.info("Initiated multipart upload with ID: " + uploadId);

                    return uploadParts(filePath, bucketName, key, uploadId)
                            .thenCompose(completedParts -> {
                                // Sort parts by part number as required by S3
                                completedParts.sort((a, b) -> a.partNumber() - b.partNumber());

                                return s3Client.completeMultipartUpload(req -> req
                                                .bucket(bucketName)
                                                .key(key)
                                                .uploadId(uploadId)
                                                .multipartUpload(builder -> builder.parts(completedParts)))
                                        .thenApply(completeResponse -> {
                                            String eTag = completeResponse.eTag();
                                            LOGGER.info("Completed multipart upload for " + key + " with ETag: " + eTag);
                                            return key;
                                        });
                            })
                            .exceptionallyCompose(ex -> {
                                // Abort the multipart upload on failure
                                LOGGER.warning("Upload failed, aborting multipart upload: " + ex.getMessage());
                                return s3Client.abortMultipartUpload(req -> req
                                                .bucket(bucketName)
                                                .key(key)
                                                .uploadId(uploadId))
                                        .thenApply(v -> {
                                            throw new CompletionException("Upload failed: " + ex.getMessage(), ex);
                                        });
                            });
                });
    }

    /**
     * Upload all parts of a large file.
     */
    private CompletableFuture<List<CompletedPart>> uploadParts(Path filePath, String bucketName, String key, String uploadId) {
        try {
            long fileSize = Files.size(filePath);
            long partSize = DEFAULT_PART_SIZE;
            long numParts = (fileSize + partSize - 1) / partSize; // Round up

            List<CompletableFuture<CompletedPart>> partFutures = new ArrayList<>();

            for (int i = 0; i < numParts; i++) {
                long position = i * partSize;
                long size = Math.min(partSize, fileSize - position);
                int partNumber = i + 1; // Part numbers start at 1

                partFutures.add(uploadPart(filePath, bucketName, key, uploadId, position, size, partNumber));
            }

            return CompletableFuture.allOf(partFutures.toArray(new CompletableFuture[0]))
                    .thenApply(v -> partFutures.stream().map(CompletableFuture::join).collect(Collectors.toList()));
        } catch (IOException e) {
            return CompletableFuture.failedFuture(e);
        }
    }

    /**
     * Upload a single part of a multipart upload.
     */
    private CompletableFuture<CompletedPart> uploadPart(Path filePath, String bucketName, String key, String uploadId,
                                                        long position, long size, int partNumber) {
        UploadPartRequest request = UploadPartRequest.builder()
                .bucket(bucketName)
                .key(key)
                .uploadId(uploadId)
                .partNumber(partNumber)
                .contentLength(size)
                .build();

        return CompletableFuture.supplyAsync(() -> {
            try (FileChannel channel = FileChannel.open(filePath, StandardOpenOption.READ)) {
                ByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, position, size);

                return AsyncRequestBody.fromByteBuffer(buffer);
            } catch (IOException e) {
                throw new CompletionException("Failed to read file part", e);
            }
        }, executorService).thenCompose(requestBody ->
                s3Client.uploadPart(request, requestBody)
                        .thenApply(response -> {
                            LOGGER.info("Completed part " + partNumber);
                            return CompletedPart.builder()
                                    .partNumber(partNumber)
                                    .eTag(response.eTag())
                                    .build();
                        })
        );
    }

    /**
     * Upload all .txt files in a directory to S3
     *
     * @param dirPath Path to the directory containing .txt files
     * @param bucketName Name of the target bucket
     * @param baseKey Base key (prefix) in the bucket
     * @return CompletableFuture representing the upload operation with list of uploaded keys
     */
    public CompletableFuture<List<String>> uploadTxtFiles(Path dirPath, String bucketName, String baseKey) {
        if (!Files.isDirectory(dirPath)) {
            return CompletableFuture.failedFuture(new IllegalArgumentException("Not a directory: " + dirPath));
        }

        return CompletableFuture.supplyAsync(() -> {
            try {
                List<Path> txtFiles = new ArrayList<>();
                try (DirectoryStream<Path> stream = Files.newDirectoryStream(dirPath, "*.txt")) {
                    stream.forEach(txtFiles::add);
                }

                LOGGER.info("Found " + txtFiles.size() + " .txt files to upload in " + dirPath);

                List<CompletableFuture<String>> uploadFutures = new ArrayList<>();

                for (Path file : txtFiles) {
                    String fileName = file.getFileName().toString();
                    String key = baseKey.isEmpty() ? fileName : baseKey + "/" + fileName;

                    uploadFutures.add(uploadFile(file, bucketName, key));
                }

                CompletableFuture<Void> allUploads = CompletableFuture.allOf(
                        uploadFutures.toArray(new CompletableFuture[0]));

                return allUploads.thenApply(v ->
                        uploadFutures.stream()
                                .map(CompletableFuture::join)
                                .collect(Collectors.toList())
                ).join();
            } catch (IOException e) {
                throw new CompletionException("Failed to upload .txt files: " + e.getMessage(), e);
            }
        }, executorService);
    }

    @Override
    public void close() {
        executorService.shutdown();
        try {
            if (!executorService.awaitTermination(30, TimeUnit.SECONDS)) {
                executorService.shutdownNow();
            }
        } catch (InterruptedException e) {
            executorService.shutdownNow();
            Thread.currentThread().interrupt();
        }

        s3Client.close();
    }

    /**
     * Main method for demonstration.
     */
    public static void main(String[] args) throws Exception {
        String bucketName = "demo";
        String localstackEndpoint = "https://localhost.localstack.cloud:4566";
        Path path = Paths.get("D:\\data\\");

        try (S3Uploader uploader = new S3Uploader(localstackEndpoint)) {
            // Ensure bucket exists
            uploader.ensureBucketExists(bucketName).join();

            // Upload directory with all files
            List<String> uploadedKeys = uploader.upload(path, bucketName, "").join();

            System.out.println("Uploaded " + uploadedKeys.size() + " files from " + path);
            uploadedKeys.forEach(key -> System.out.println("  - " + key));

            // Alternatively, upload only .txt files
            // List<String> uploadedTxtFiles = uploader.uploadTxtFiles(path, bucketName, "txt").join();
            // System.out.println("Uploaded " + uploadedTxtFiles.size() + " .txt files from " + path);
        }
    }
}