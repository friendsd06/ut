"""
Easy to read configuration manager for different environments
"""

# Standard library imports
import logging
from dataclasses import dataclass, field
from enum import Enum, auto
from pathlib import Path
from typing import Dict, Optional

# Third-party imports
import yaml

# Set up logging with a nice format
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==============================================
#               Environment Types
# ==============================================
class Environment(Enum):
    """Different environments where our code can run"""
    LOCAL = auto()      # Your computer
    DEV = auto()        # Development
    TEST = auto()       # Testing
    PREPROD = auto()    # Pre-production
    PROD = auto()       # Production
    
    @classmethod
    def from_str(cls, env_name: str) -> 'Environment':
        """Convert string to environment type"""
        try:
            return cls[env_name.upper()]
        except KeyError:
            valid_environments = ', '.join(env.name.lower() for env in cls)
            raise ValueError(
                f"Invalid environment: '{env_name}'\n"
                f"Please use one of: {valid_environments}"
            )

# ==============================================
#               Data Classes
# ==============================================
@dataclass
class DatabricksEnv:
    """Databricks connection settings"""
    # Basic connection
    hostname: str
    port: int
    httpPath: str
    
    # Security settings
    ssl: str
    AuthMech: str
    transportMode: str
    
    # Database settings
    ConnCatalog: str
    UseNativeQuery: str
    
    # Proxy settings
    UseProxy: str
    ProxyHost: str
    ProxyPort: str

    @classmethod
    def get_default_local(cls) -> 'DatabricksEnv':
        """Default settings for local development"""
        return cls(
            hostname="localhost",
            port=10000,
            transportMode="http",
            ssl="0",
            ConnCatalog="local_catalog",
            AuthMech="0",
            UseProxy="0",
            UseNativeQuery="1",
            ProxyHost="",
            ProxyPort="0",
            httpPath="/sql/1.0/warehouses/localWarehouse"
        )

    def get_connection_params(self) -> dict:
        """Get connection parameters in a simple format"""
        return {
            "host": self.hostname,
            "port": self.port,
            "transport_mode": self.transportMode,
            "ssl": self.ssl == "1",
            "catalog": self.ConnCatalog,
            "auth_mechanism": int(self.AuthMech),
            "use_proxy": self.UseProxy == "1",
            "use_native_query": self.UseNativeQuery == "1",
            "proxy_host": self.ProxyHost,
            "proxy_port": int(self.ProxyPort),
            "http_path": self.httpPath
        }

@dataclass
class S3Env:
    """Storage settings"""
    base_path: str

    @classmethod
    def get_default_local(cls) -> 'S3Env':
        """Default storage settings for local development"""
        return cls(base_path="file:///tmp/data/")

    def get_full_path(self, relative_path: str) -> str:
        """Combine base path with relative path"""
        return str(Path(self.base_path.rstrip("/")) / relative_path.lstrip("/"))

@dataclass
class TableConfig:
    """Settings for database tables"""
    query: str      # SQL query to get data
    s3_path: str    # Where to save the data
    format: str     # File format (parquet, csv, etc.)
    mode: str       # How to handle existing data

    def validate(self) -> None:
        """Check if settings are valid"""
        # Valid file formats
        allowed_formats = {
            "parquet",  # Efficient columnar storage
            "csv",      # Simple text format
            "delta",    # Versioned parquet
            "json"      # Flexible text format
        }
        
        # Valid write modes
        allowed_modes = {
            "overwrite",  # Replace existing data
            "append",     # Add to existing data
            "ignore",     # Skip if exists
            "error"       # Fail if exists
        }

        # Check format
        if self.format.lower() not in allowed_formats:
            raise ValueError(
                f"Format '{self.format}' is not allowed.\n"
                f"Please use one of: {', '.join(allowed_formats)}"
            )

        # Check mode
        if self.mode.lower() not in allowed_modes:
            raise ValueError(
                f"Mode '{self.mode}' is not allowed.\n"
                f"Please use one of: {', '.join(allowed_modes)}"
            )

@dataclass
class FullConfig:
    """Complete configuration for all environments"""
    databricks: Dict[str, DatabricksEnv] = field(default_factory=dict)
    s3_settings: Dict[str, S3Env] = field(default_factory=dict)
    tables: Dict[str, TableConfig] = field(default_factory=dict)

    def validate(self) -> None:
        """Check if all required settings are present"""
        # Check for required environments
        required_envs = {"dev", "test", "preprod", "prod"}
        
        # Check each section
        for section_name in ["databricks", "s3_settings"]:
            section = getattr(self, section_name)
            missing_envs = required_envs - set(section.keys())
            
            if missing_envs:
                raise ValueError(
                    f"Missing environments in {section_name}: "
                    f"{', '.join(missing_envs)}"
                )

        # Validate each table's settings
        for table_name, table_config in self.tables.items():
            try:
                table_config.validate()
            except ValueError as e:
                raise ValueError(f"Invalid settings for table '{table_name}': {str(e)}")

# ==============================================
#           Configuration Reader
# ==============================================
class ConfigReader:
    """Reads and manages configuration settings"""

    def __init__(self, config_file: str):
        """Initialize with path to config file"""
        self.config_file = config_file
        self.raw_config = self._load_yaml()
        self.config = self._build_full_config()
        
        # Validate everything
        self.config.validate()
        logger.info(f"Successfully loaded config from: {config_file}")

    def _load_yaml(self) -> dict:
        """Read and parse the YAML config file"""
        try:
            config_path = Path(self.config_file)
            
            # Check if file exists
            if not config_path.exists():
                raise FileNotFoundError(f"Config file not found: {self.config_file}")
            
            # Read and parse YAML
            with open(config_path, "r", encoding="utf-8") as f:
                data = yaml.safe_load(f) or {}
                
            # Check if it's a dictionary
            if not isinstance(data, dict):
                raise ValueError(f"Config file must contain a dictionary")
                
            return data
            
        except yaml.YAMLError as e:
            raise ValueError(f"Error parsing YAML: {str(e)}")

    def _build_full_config(self) -> FullConfig:
        """Build complete configuration from YAML data"""
        try:
            # Check for required sections
            required_sections = ["databricks", "s3_settings", "tables"]
            for section in required_sections:
                if section not in self.raw_config:
                    raise KeyError(f"Missing required section: '{section}'")

            # Build Databricks settings
            db_envs = {"local": DatabricksEnv.get_default_local()}
            db_section = self.raw_config["databricks"]
            for env in ["dev", "test", "preprod", "prod"]:
                if env not in db_section:
                    raise KeyError(f"Missing Databricks settings for: {env}")
                
                # Convert port to int if needed
                env_config = db_section[env].copy()
                if isinstance(env_config.get("port"), str):
                    env_config["port"] = int(env_config["port"])
                
                db_envs[env] = DatabricksEnv(**env_config)

            # Build storage settings
            s3_envs = {"local": S3Env.get_default_local()}
            s3_section = self.raw_config["s3_settings"]
            for env in ["dev", "test", "preprod", "prod"]:
                if env not in s3_section:
                    raise KeyError(f"Missing storage settings for: {env}")
                s3_envs[env] = S3Env(**s3_section[env])

            # Build table settings
            table_configs = {}
            table_section = self.raw_config["tables"]
            for table_name, table_data in table_section.items():
                table_configs[table_name] = TableConfig(**table_data)

            return FullConfig(
                databricks=db_envs,
                s3_settings=s3_envs,
                tables=table_configs
            )

        except Exception as e:
            raise ValueError(f"Error building configuration: {str(e)}")

    def get_full_config(self) -> FullConfig:
        """Get complete configuration"""
        return self.config

    def get_databricks_env(self, env: str) -> DatabricksEnv:
        """Get Databricks settings for specific environment"""
        env_obj = Environment.from_str(env)
        env_key = env_obj.name.lower()
        
        if env_key not in self.config.databricks:
            raise ValueError(f"No Databricks settings found for: {env}")
            
        return self.config.databricks[env_key]

    def get_s3_env(self, env: str) -> S3Env:
        """Get storage settings for specific environment"""
        env_obj = Environment.from_str(env)
        env_key = env_obj.name.lower()
        
        if env_key not in self.config.s3_settings:
            raise ValueError(f"No storage settings found for: {env}")
            
        return self.config.s3_settings[env_key]

    def get_table_config(self, table_name: str) -> TableConfig:
        """Get settings for specific table"""
        if table_name not in self.config.tables:
            raise ValueError(f"No settings found for table: {table_name}")
            
        return self.config.tables[table_name]


# ==============================================
#               Example Usage
# ==============================================
def show_environment_info(reader: ConfigReader, env: str) -> None:
    """Show settings for a specific environment"""
    try:
        # Get Databricks settings
        db_config = reader.get_databricks_env(env)
        logger.info(f"\n{env.upper()} Environment Settings:")
        logger.info("-" * 50)
        logger.info(f"Databricks Host: {db_config.hostname}")
        logger.info(f"Port: {db_config.port}")
        logger.info(f"Catalog: {db_config.ConnCatalog}")
        
        # Get storage settings
        storage = reader.get_s3_env(env)
        logger.info(f"Storage Location: {storage.base_path}")
        
    except Exception as e:
        logger.error(f"Error showing {env} environment info: {str(e)}")

def show_table_info(reader: ConfigReader, table_name: str, env: str) -> None:
    """Show settings for a specific table in an environment"""
    try:
        # Get table configuration
        table = reader.get_table_config(table_name)
        storage = reader.get_s3_env(env)
        
        logger.info(f"\nTable: {table_name}")
        logger.info("-" * 50)
        logger.info(f"Query: {table.query}")
        logger.info(f"Storage Path: {storage.get_full_path(table.s3_path)}")
        logger.info(f"Format: {table.format}")
        logger.info(f"Write Mode: {table.mode}")
        
    except Exception as e:
        logger.error(f"Error showing table '{table_name}' info: {str(e)}")

def main():
    """Main function to demonstrate usage"""
    try:
        # Create config reader
        logger.info("Loading configuration...")
        reader = ConfigReader("config.yml")
        
        # Show information for each environment
        for env in ["local", "dev", "test", "preprod", "prod"]:
            show_environment_info(reader, env)
        
        # Show information for each table in development environment
        logger.info("\nTable Configurations (DEV Environment):")
        for table_name in ["rgdfdfgdfgd_xref", "customer_dim"]:
            show_table_info(reader, table_name, "dev")
            
        logger.info("\nConfiguration loaded successfully!")
        
    except Exception as e:
        logger.error(f"Error in main function: {str(e)}")
        raise

# ==============================================
#            Run the program
# ==============================================
if __name__ == "__main__":
    main()